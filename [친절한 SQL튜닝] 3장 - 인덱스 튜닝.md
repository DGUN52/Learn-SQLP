3.1 테이블 액세스 최소화
- SQL튜닝은 랜덤IO와의 전쟁

  3.1.1 테이블 랜덤 액세스
    - 인덱스 ROWID는 물리주소? 논리주소? 논리주소에 가깝다. (인덱스 ROWID는 데이터파일 번호, 오브젝트 번호, 블록 번호로 이루어짐)
    - 인덱스 ROWID를 통한 테이블 접근은 포인터를 통한 접근이 아닌 DBA(Data Block Adress, 데이터가 디스크에 있는 주소)를 통한 접근이다. 메인메모리를 통한 접근보다 느리다.
    - 오라클은 버퍼캐시의 DBA(디스크 주소 정보)를 이용해 해시알고리즘으로 버퍼 블록을 찾아간다. 반면 메인 메모리 DB는 메모리 상의 주소정보(포인터)를 갖기때문에 훨씬 빠르다.
    - I/O 메커니즘 : 버퍼캐시를 찾고, DBA를 해쉬 함수에 넣어서 해시체인을 찾고 거기서 버퍼헤더를 찾는다.
    - 인덱스로 접근 시 : 리프블록에서 얻은 ROWID로 DBA를 얻고, FULL SCAN시엔 익스텐트 맵에서 읽을 블록들의 DBA 얻음
    - <b>인덱스 ROW ID는 포인터가 아님!</b>
    - 인덱스 ROW ID는 포인터가 아니며, 디스크 상의 테이블 레코드를 찾아가기 위한 논리적인 주소 정보.
    - 버퍼캐시에서 테이블 블록을 먼저 찾아보고 없을 때에만 디스크에서 블록을 잃는다,
    - 버퍼캐시에 데이터가 있더라도 DBA해싱과 래치획득을 매번 반복해야한다. 경합마저 발생 가능
    - TABLE ACCESS (BY INDEX ROWID) OF '고객' 와 같은 ROWID를 통한 데이터 접근은 생각보다 고비용이다!
 
  3.1.2 인덱스 클러스터링 팩터 CF ~= 군집성 계수
  : 특정 컬럼을 기준으로 같은 값을 갖는 데이터가 서로 모여있는 정도 (물리적으로)
  - 물리적으로 같은 블록에 위치하면 (래치 획득과 체인 스캔 과정)을 생략하고(블록 IO를 생략하고) 바로 데이터에 접근할 수 있기 때문

  3.1.3 인덱스 손익분기점
  - Index Range Scan에 의한 테이블 액세스가 Table Full Scan보다 느려지는 지점
  - 이유
    - Table Full Scan : 시퀀셜 액세스, Multiblock IO
    - Index Range Scan : 랜덤 액세스, Single Block IO
  - 보통 5~20%의 낮은 수준을 이룬다. CF가 좋으면 90%까지 상승, 테이블 데이터가 100만, 1000만이 넘어가면 사실상 없는 수준

- ※ 07/14 129p ~ 145p ※

3.1.4 인덱스 컬럼 추가
- 일반적으로 튜닝을 위해 사용하는 기법 : 기존에 존재하는 인덱스에 <b>자주 조건으로 사용되는 컬럼을 추가</b>한다.

3.1.5 인덱스만 읽고 처리
- <b>Covered Index</b>
  - 인덱스로 스캔한 데이터가 버리게 되는 것은 거의 없지만 절대 데이터량이 많아서 느려지는 경우 어쩔 수 없다.
  - 하지만 쿼리에 사용된 모든 컬럼을 인덱스에 추가하여 테이블 액세스를 없애는 방법이 있다. 
- <b>Include Index</b>
  - 인덱스와 별도로 지정한 컬럼을 리프 레벨에 함께 저장하는 기능(SQL Server)
    - ex1) create index emp_x01 on emp (deptno) include (sal)
    - ex2) create index emp_x02 on emp (deptno, sal)
    - ex1은 수직탐색에는 sal을 사용할 수 없다. sal컬럼은 테이블 액세스를 줄이기 위해서만 사용된다.

3.1.6 인덱스 구조 테이블
- 랜덤 액세스가 발생하지 않도록 테이블 자체를 인덱스 구조로 구성. IOT; Index-Organized Table / Clustered Index
- 인덱스가 ROWID를 갖지 않고 테이블 데이터 자체를 갖는다. 인덱스 리프 블록 = 데이터 블록
- oracle에서 create table 구문 맨 끝에 organization index; 로 구성 (일반테이블은 organization heap)
- ex) create table index_org_t ( a number, b varchar(10), constraint index_org_t_pk primary key (a) ) organization index;
- 랜덤 액세스가 아닌 시퀀셜 액세스 -> Between/부등호 조건에도 유리

3.1.7 클러스터 테이블
- 인덱스 클러스터/해시 클러스터
- <b>인덱스 클러스터 테이블</b>
  - 클러스터 키 값이 같은 레코드를 한 블록에 모아서 저장하는 구조. 정렬하지는 않음
  - 한 블록에 담기지 않을 경우 새로운 블록에 할당해서 클러스터 체인으로 연결
  - 여러 테이블 레코드를 한 블록에 저장할 수도 있음 (다중 테이블 클러스터)
  - ex)
    - create cluster c_dept# ( deptno number(2) ) <b>index</b>;
    - create index c_dept#_index on cluster c_dept#;
    - create table dept( deptno number(2) not null, dname varchar2(14) not null, loc varchar2(13) ) cluster c_dept#(deptno);
  - 일반 인덱스는 테이블 레코드와 1:1 관계지만, 클러스터 인덱스는 테이블 레코드와 1:M 관계이다. (ex. deptno) 따라서 중복값이 없다.
  - 인덱스 클러스터 테이블은 랜덤 액세스가 값 하나당 한 번 밖에 일어나지 않음.(클러스터 체인을 스캔할 때 생기는 랜덤 액세스 제외)
    - 따라서 넓은 범위를 읽어도 비효율 X
- <b>해시 클러스터 테이블 테이블</b>
  - 인덱스를 사용하지 않고 해시 알고리즘을 사용해 클러스터를 찾아는 것만 다름

3.2 부분범위 처리 활용

3.2.1 부분범위 처리
- DBMS는 일정량의 데이터를 나누어서 전송한다. 자바의 기본 Array Size는 10으로 Statement객체의 setFetchSize 메소드로 변경할 수 있다.
  - 최초 rs.next() 호출 시 10건을 캐시에 저장하고 다음 9번의 호출은 캐시에서 읽는다.
- 정렬조건이 있을 시 DB서버는 전체 결과를 읽어야 데이터를 전송하기 시작한다.
  - order by 조건이 선두인 인덱스가 있을 경우 부분 범위 처리 가능
- 따라서 대용량 데이터를 전송할 때 그 데이터를 거의 버리지 않는다면 Array Size를 증가할 필요가 있고 (Fetch 횟수 감소)
- 보통 데이터를 로드하다가 앞부분만 읽고 버리게된다면 Array Size를 줄일 필요가 있다. (반환속도 증가)

3.2.2 부분범위 처리 구현
- 자바 프레임워크로 구현되어있다.

3.2.3 OLTP 환경에서 부분범위 처리에 의한 성능개선 원리
- 인덱스와 부분범위 처리 원리는 활용하여 OLTP환경 등에서 극적인 성능개선 효과를 얻을 수 있다.
  - 조건절의 컬럼을 선두조건, 정렬조건을 후행조건으로 인덱스를 구성한다
- 배치IO : 디스크 IO를 즉각즉각 처리하지 않고 일정량 쌓이면 한꺼번에 처리
  - 데이터 정렬 이슈 : 배치 IO가 작동하면 데이터 정렬 순서가 매번 다를 수 있다.
  - 인덱스로 정렬이 보장돼있는 쿼리라도 Batch 힌트로 batch 기능이 작동한 경우 실행계획에 sort order by 가 포함될 수 있다.



- ※ 07/15(토) 146p ~ 172p ※



3.3 인덱스 스캔 효율화
- IOT, 클러스터, 파티션은 효과적이지만 성능검증을 위한 테스트 필요
- 일반적인 튜닝 기법은 인덱스 컬럼 추가

3.3.1 인덱스 탐색
- (B, 3) 레코드를 찾고자 할 때 루트 블록에 (A,3), (B,3), ...이 있다면 (B,3)이 가리키는 리프블록이 아닌 그 전 블록인 (A,3)이 가리키는 리프블록으로 찾아가야한다.

3.3.2 인덱스 스캔 효율성
- 선행컬럼이 인덱스에 없다면 스캔에 비효율이 발생한다.

3.3.3 액세스 조건과 필터 조건
- 인덱스 액세스 조건 : 인덱스 스캔 범위를 결정하는 조건절. 수직탐색을 통해 스캔 시작점 결정, 익덱스 리프 블록스캔 중 어디서 멈출지 결정에 영향
- 인덱스 필터 조건 : 테이블에 액세스 할 지 결정하는 조건절
- 테이블 필터 조건 : 쿼리 수행 다음 단계로 전달하거나 최종 결과집합에 포함할지를 결정
- (비용 = 인덱스 수직 탐색 + 인덱스 수평 탐색 + 테이블 랜덤 액세스)
- (   = 인덱스 루트와 브랜치에서 읽는 블록 수 + 인덱스 리프 블록 스캔 블록 수 + 테이블 액세스 과정에서 읽는 블록 수)

3.3.4 비교연산자 종류와 컬럼 순서에 따른 군집성
- 선행 컬럼이 모두 '=' 조건인 상태에서 첫번째 나타나는 범위검색까지만 만족하는 인덱스 레코드는 모드 연속해서 모여있다.
- -> 선행컬럼들의 조건이 모두 =인 컬럼들과, 첫번째 범위검색까지는 <b>인덱스 액세스 조건</b>, 나머지 인덱스 컬럼 조건은 모두 <b>인덱스 필터 조건</b>

3.3.5 인덱스 선행 컬럼이 = 조건이 아닐 때 생기는 비효율
- 읽어야 되는 레코드들이 나뉘게 된다. (군집성이 없어지게 된다. = 인덱스 CF 저하)

3.3.6 BETWEEN을 IN-LIST로 전환
- 운영시스템에서 인덱스 구성을 바꾸는 것은 어렵다.
- 범위검색 BETWEEN을 IN-List로 바꿀 때 효율이 증가하는 경우가 있음.
  - IN-List 조건이 많지 않아야 한다.
    - BETWEEN -> 리프블록을 많이 읽음 / IN-List -> 브랜치 블록을 많이 읽음 (수직 탐색이 늘어남), Depth가 깊을수록 IN-List의 비용 증가
  - 레코드가 멀이 떨어져 있을때 효율성의 증가가 확실함(BETWEEN의 리프 블록 탐색이 생략됨)
    - 멀리 떨어져 있지 않다면 효과가 없거나 줄어들거나 역효과가 날 수도 있다.
- <i>where 인터넷매물 between 1 and 3</i> → <i>where 인터넷매물 in ('1','2','3')</i>
  - 실행계획에 INLIST ITERATOR로 변경됨
- Index Skip Scan으로 유도해도 비슷한 효과를 얻음.

3.3.7 Index Skip Scan 활용
- 3.3.6을 실제 해본 결과들. 생략.


- ※ 07/16(일) 173p ~ 202p ※


3.3.8 IN 조건은 '='인가
- IN-List Iterator 방식으로 풀리는 경우만 그렇다.
- 하지만 대부분의 경우 억지로 IN-List Iterator 방식으로 풀기 위해 인덱스 구성을 변경하거나 하는 것은 비효율적이다.
  - ex) (고객번호, 상품ID) 인덱스가 있을 때 where 상품ID in (10, 20, 30) 이런식으로 조회하면 상품ID는 인덱스 리프블록 하나(혹은 둘)에 밀집되어있기 때문에 IN-List Iterator 방식으로 풀 필요가 없이 필터조건으로서의 역할만 수행하면 된다. 반대는 오히려 역효과.
  - 마찬가지로 (상품ID, 상품구분코드) 인덱스가 있을 때, where 상품구분코드 in ( 'GX', 'KR' ) 은 필터조건으로 처리되며, 억지로 IN-List Iterator 방식을 사용하는 것은 비효율적이다.
 
- IN-List Iterator 처리방식 유도/비유도 힌트 : NUM_INDEX_KEYS
  - ex) select /*+ num_index_keys(a 고객별가입상품_X1 1) */ *
  - 여기서 1은 첫번째 컬럼까지만 액세스 조건으로 활용하라는 의미
- 비유도시(액세스 필터 조건으로만 활용하고자 할 때) 조건절을 가공함으로써 필터조건으로 사용되게 할 수도 있다.
  - ex) where 상품ID || '' in (~)
    - 상품ID를 가공하는 연산을 추가하였다.

3.3.9 BETWEEN과 LIKE 스캔 범위 비교
- 편의를 위한 LIKE가 비효율적인 탐색을 함

3.3.10 범위검색 조건을 남용할 때 생기는 비효율
- 개발단계의 편의를 위해서 옵션조건 여부에 상관없이 LIKE + 기본값으로 통일하면 리소스 낭비가 발생한다.

3.3.11 다양한 옵션 조건 처리 방식의 장단점 비교
- OR조건
  - 인덱스 선두 컬럼에 대한 옵션 조건에 OR조건을 사용해선 안됨
    - ex) where (:cust_id is null or 고객ID = :cust_id)
    - 옵티마이저에 의한 OR Expansion 쿼리 변환이 작동하지 않는다.
    - 위의 경우 (고객ID + 거래일자)인덱스는 사용할 수 없지만 (거래일자 + 고객ID) 인덱스는 사용할 수 있다.
    - 하지만 고객ID는 (인덱스 필터가 아닌)테이블 액세스 단계에서 필터 조건으로 쓰이게 된다. 즉 인덱스에 포함될 필요조차 없다.
  - 다음과 같은 경우엔 OR 조건을 사용해도 무방
    - 인덱스 액세스 조건으로 사용 불가
    - 인덱스 필터 조건으로 사용 불가
    - 테이블 필터 조건으로만 사용 가능
    - 단 인덱스 구성 컬럼 중 하나 이상이 NN컬럼이면 인덱스 필터 조건으로 사용될 수 있다.(18c부터)
  - OR조건의 장점은 NULL 허용 컬럼에 결과집합이 보장되는 것 뿐이다.(결과값이 무조건 나온다.)

- LIKE/BETWEEN 조건 활용
  - 변별력이 있고 해당하는 레코드가 많지 않은 상황에서는 좋은 선택이다.
  - 필수 조건 컬럼을 인덱스 선두에 두고 액세스 조건으로 사용하면, LIKE/BETWEEN이 인덱스 필터 조건이어도 좋은 성능을 냄
  - 필수조건이 =조건이면 인덱스 액세스 조건으로 활용되기때문에 최적의 성능
  - 다만 선두컬럼의 조건이나 like/between 조건 컬럼의 <b>입력값</b>이 null값일 경우 문제가 생길 수 있다.(Index Range Scan으로 Full scan 범위 처리)
  - 따라서 효율이 떨어지지 않으려면 조건절이 다음과 같은 조건에 해당되는것을 지양해야한다.
    1. 인덱스 선두 컬럼(BETWEEN, LIKE)
    2. NULL 허용 컬럼(BETWEEN, LIKE)
    3. 숫자형 컬럼(LIKE)
    4. 가변 길이 컬럼(LIKE)


- ※ 07/17(월) 202p ~ 218p ※

  - 다시얘기하면
    1. 인덱스 선두 컬럼에 대한 옵션 조건을 LIKE/BETWEEN으로 처리하면 안된다.
    2. NULL허용 컬럼에 대한 옵션 조건을 LIKE/BETWEEN으로 처리하면 안된다.
      - null데이터를 가지고 있는 로우가 결과집합에서 제외된다.
    3. 숫자형이면서 인댁스 액세스 조건으로 사용 가능한 컬럼에 대해서 LIKE방식을 사용하면 안 된다.
      - 문자열로 자동 형변환되면서 액세스조건이 필터조건이 되어버린다.
    4. 가변 길이 컬럼에 LIKE를 사용하면 원하지 않는 결과가 포함된다.
      - 따라서 length에 대한 조건도 같이 걸어주어야한다.
      - 또는 like :cust_nm 처럼 정확한 고객명을 찾게 만든다.

- <b>UNION ALL 활용</b>
- UNION ALL을 활용해 입력값이 있는지 없는지에 따라 SQL중 하나만 실행되게 한다.
  - ex) select * from 거래 where :cust_id is null and 거래일자 between a and b
  - union all select * from 거래 where :cust_id is not null and 고객ID = :cust_id and 거래일자 between a and b
  - 이 방법으로 :cust_id 변수에 값이 입력되던 말던 최적으로 사용한다.

- <b>NVL/DECODE 함수 활용</b>
  - ex1) select * from 거래 where 고객ID = nvl(:cust_id, 고객ID) and 거래일자 between a and b
  - ex2) select * from 거래 where 고객ID = decode(:cust_id, null 고객ID, :cust_id) and 거래일자 between a and b
  - 이 방법을 쓰면 옵션 조건 컬럼을 인덱스 액세스 조건으로 사용가능하다. 즉 UNION ALL보다 단순하면서 UNION ALL과 같은 성능을 낸다.
  - NVL/DECODE 함수를 여러번 사용하면 가장 변별력이 좋은(카디널리티가 낮은) 컬럼을 기준으로 한번만 OR Expansion이 수행된다.

3.3.12 함수호출부하 해소를 위한 인덱스 구성
- PL/SQL함수의 성능적 특성
- 느린 이유
  1. 가상머신상에서 실행되는 인터프리터 언어
    - PL/SQL함수는 가상머신(PL/SQL 엔진)이 런타임 시 해석하면서 실행하기때문에 느리다.
    - (Native코드로 컴파일된 Built-in 함수가 아닌 인터프리터 언어)
  2. 호출 시마다 컨텍스트 스위칭 발생
  3. 내장 SQL에 대한 Recursive Call 발생
    - 함수 내부에 SQL이 있으면 함수의 반복 횟수만큼 SQL도 반복하기 때문에 부하가 크다
- 따라서 조인문으로 처리하도록 노력한다.
- 하지만 로직이 복잡하면 PL/SQL함수를 사용할 수 밖에 없는데, 액세스 조건을 고려해 인덱스를 구성하여 함수 호출횟수를 줄인다.

- <b>효과적인 인덱스 구성을 통한 함수호출 최소화</b>
  - :조건절에서 함수를 호출하기 전에 다른 조건을 걸어서 함수 호출 횟수가 적어지게 한다.
  - 함수를 호출하는 조건절의 컬럼을 포함해 모든 컬럼이 인덱스 액세스 조건이라면 PL/SQL 함수는 단 한번만 수행된다.


3.4 인덱스 설계

3.4.1 인덱스 설계가 어려운 이유
- 인덱스가 너무 많은 경우 다양한 단점이 생김
  - DML성능 저하 (TPS저하)
  - 데이터베이스 사이즈 증가 (디스크 공간 낭비)
  - 데이터베이스 관리 및 운영 비용 상승(복제, 백업, 재구성 등)
- 인덱스에 신규 데이터 입력 시 INSERT할 위치를 찾기 위해
  - 수직 탐색으로 입력할 블록을 찾음
  - 블록에 여유 공간이 없으면 인덱스 분할
- 따라서 인덱스 개수를 최소화 하면서 쿼리 성능을 높여야 하는 어려운 난이도를 가진다.

3.4.2 가장 중요한 두가지 선택 기준
- 인덱스 스캔의 가장 정상적이고 일반적인 방식은 Index Range Scan
  - 이를 위해서는 선두 컬럼이 조건절에 반드시 사용되어야한다.
  1. 첫번째 기준은 조건절에 항상 혹은 자주 사용하는 컬럼을 선정하는 것
  2. 두번째 기준은 '=' 조건으로 자주 조회하는 컬럼을 앞쪽에 두는 것

3.4.3 스캔 효율성 이외의 판단 기준
- 그 외의 판단 기준은 다음과 같다.
  - <b>수행 빈도</b>x  
  - 업무상 중요도
  - 클러스터링 팩터
  - 데이터량
  - DML부하 (기존 인덱스 개수, 초당 DML발생량, 자주 갱신하는 컬럼 포함 여부 등)
  - 저장 공간
  - 인덱스 관리 비용 등
- 이와 같은 다양한 판단 기준이 있기 때문에 설계자에 따라 튜닝방법도 달라질 수 있다.

- NL조인의 Inner쪽 (use_nl(★)의 별부분) 테이블의 인덱스 스캔 과정에 생기는 비효율은 성능에 큰 악영향을 끼친다.
  - NL 조인의 Ineer쪽 인덱스는 = 조건 컬럼을 선두에 두는 것이 중요하고
  - 가능한 인덱스 필터링에서 끝내서 테이블 액세스를 없애도록 구성해야한다.
  - 저용량 테이블이라면 인덱스 자체가 필요가 없고,
  - 초대용량 테이블이라면 인덱스 하나라도 최대한 줄여야한다.

3.4.4 공식을 초월한 전략적 설계
- 가장 핵심적인 액세스 경로 한두개를 최적 인덱스로 설계하고 나머지 인덱스를 만족할만한 성능으로 구성할 수 있어야 한다.
- 인덱스 스캔 효율보다 테이블 액세스의 부하가 더 많다면 선두컬럼 설정으로 인덱스 스캔 효율을 꽤하는것을 제쳐두고 테이블 액세스가 발생하지 않게 더 신경쓴다.

3.4.5 소트 연산을 생략하기 위한 컬럼 추가
- 조건절에 사용하지 않는 컬럼이라도 정렬을 위한 소트연산을 생략하기 위해 인덱스에 포함시킨다.
- =조건으로 사용되는 컬럼은 ORDER BY 절에 사용되는 컬럼들 앞쪽에, =조건으로 사용되지 않는 컬럼들은 뒤쪽에 배치하여 인덱스 구성
- 뒤쪽에 배치하는 인덱스들은 카디널리티가 낮다면 구성 뒤쪽에 넣고, 카디널리티가 높다면 굳이 구성에 넣을 필요가 없다.
- IN 조건절의 경우 IN-List Iterator 방식으로 실행되면 sort연산을 절대 생략할 수 없기때문에 인덱스 후행컬럼에 배치해서 인덱스 필터조건으로 사용되게 해야 한다.



- ※ 07/18(화) 218p ~ 241p ※



3.4.6 결합 인덱스 선택도
- 선택도가 낮으면 인덱스를 생성할 만 하다!(카디널리티가 낮으면, 변별력이 높으면.)
- 선택도가 낮으면 다음과 같은 경우에 유리하다
  - 조건컬럼이 아닌 결과컬럼에 인덱스를 거는 경우
  - 테이블의 데이터가 방대할 경우
  - 범위조건이 많이 사용되는 조건컬럼
- 위와 같은 경우를 제외하면 평균적으로는 선택도가 높으면(카디널리티가 높으면, 고유값이 많으면) 필터링되는 레코드가 많아져서 효율이 올라간다.


